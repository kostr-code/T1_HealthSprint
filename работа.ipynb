{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b4ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b50915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the datasets using the specified parameters\n",
    "data = pd.read_csv('data_for_spb_hakaton_entities1-Table 1.csv', skiprows=1, sep=';', encoding='utf-8')\n",
    "history_table = pd.read_csv('history-Table 1.csv', skiprows=1, sep=';', encoding='utf-8')\n",
    "sprint_table = pd.read_csv('sprints-Table 1.csv', skiprows=1, sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b310052",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_categories = {\n",
    "    \"К выполнению\": ['Создано', 'Готово к разработке', 'Анализ', 'В ожидании', 'Отложен'],\n",
    "    \"В работе\": ['В работе', 'Тестирование', 'Разработка', 'Подтверждение', 'Подтверждение исправления', 'СТ', 'Исправление'],\n",
    "    \"Сделано\": ['Закрыто', 'Выполнено', 'СТ Завершено', 'Отклонен исполнителем', 'Локализация']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364a95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matvey\\AppData\\Local\\Temp\\ipykernel_2420\\384267789.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  history_table['history_date'] = pd.to_datetime(history_table['history_date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "history_table['history_change'] = history_table['history_change'].fillna('')\n",
    "history_table = history_table.dropna(subset=['entity_id']).reset_index(drop = True)\n",
    "data.loc[:,'rank'] = data['rank'].replace('0|qzzywj:zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzm','0|qzzywj:')\n",
    "data.drop_duplicates(subset='entity_id')\n",
    "history_table = history_table.drop(columns=['Столбец1','Unnamed: 7'])\n",
    "data['create_date'] = pd.to_datetime(data['create_date'])  \n",
    "data['update_date'] = pd.to_datetime(data['update_date'])\n",
    "history_table['history_date'] = pd.to_datetime(history_table['history_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a30dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sprint_table['sprint_start_date'] = pd.to_datetime(sprint_table['sprint_start_date'], errors='coerce')\n",
    "sprint_table['sprint_end_date'] = pd.to_datetime(sprint_table['sprint_end_date'], errors='coerce')\n",
    "sprint_table['entity_ids'] = sprint_table['entity_ids'].apply(lambda x: eval(x) if isinstance(x, str) else [])\n",
    "sprint_data = sprint_table.explode('entity_ids').rename(columns={'entity_ids': 'entity_id'})\n",
    "sprint_data['entity_id'] = pd.to_numeric(sprint_data['entity_id'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c23fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['create_date'] = pd.to_datetime(data['create_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13eef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_distribution = data['status'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1672466",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_table['time_in_status'] = history_table.groupby('entity_id')['history_date'].diff()\n",
    "history_table = history_table.merge(data, on='entity_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae02967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = history_table.groupby(['entity_id','status'])['time_in_status'].sum().to_frame()\n",
    "group = group.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49735d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_info_with_id(i,time_start,time_end):\n",
    "    entity_id = i\n",
    "    entity_id = take_sprint_id(entity_id)\n",
    "    entity_sprint_info = sprint_table[sprint_table['entity_ids'].isin(entity_id)]\n",
    "    interval_history = history_table[(history_table['history_date'] >= time_start) & (history_table['history_date'] <= time_end)]\n",
    "    interval_history = interval_history[interval_history['entity_id'].isin(entity_id)]\n",
    "    interval_history = take_data_interval(interval_history)\n",
    "    entity_info = group[group['entity_id'].isin(entity_id)]\n",
    "    return  interval_history\n",
    "\n",
    "def take_data_interval(interval):\n",
    "    group1 = interval.groupby(['estimation'])['spent'].sum().reset_index()\n",
    "    #group1.reset_index().sum() #estimation и spent \n",
    "    total_estimation = group1['estimation'].sum()\n",
    "    total_spent = group1['spent'].sum()\n",
    "    backlog_df = interval[interval['status'] == 'Отложен'] #Бэклог задачи\n",
    "\n",
    "    return {'total_estimation': total_estimation,'total_spent':total_spent, 'backlog': len(backlog_df), 'count_normal_task':len(interval)-len(backlog_df)}\n",
    "\n",
    "def take_sprint_id(i):\n",
    "    sprints_arr = list(sprint_table['entity_ids'][i])\n",
    "    return sprints_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c965afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = take_info_with_id(1,'2023-07-13 11:07:00','2024-12-13 11:07:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e90d54a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_estimation': 2818860.0,\n",
       " 'total_spent': 163389000.0,\n",
       " 'backlog': 15,\n",
       " 'count_normal_task': 12612}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d7385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
